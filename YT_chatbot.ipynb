{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPz3LlpAp9yPhTZJeeUKzgt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samtru99/Youtube-Chatbot/blob/main/YT_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "xSfyKITMn6aw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCn_jui8kfzh"
      },
      "outputs": [],
      "source": [
        "!pip install -qU pytube moviepy pydub langchain pinecone-client tiktoken openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Youtube Extraction\n",
        "from pytube import YouTube\n",
        "from moviepy.editor import *\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "\n",
        "#OpenAI\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "\n",
        "#Langchain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
        "\n",
        "from langchain.schema import (\n",
        "    SystemMessage,\n",
        "    HumanMessage,\n",
        "    AIMessage\n",
        ")\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "import langchain\n",
        "\n",
        "#others\n",
        "import tiktoken\n",
        "import re\n",
        "import pinecone\n"
      ],
      "metadata": {
        "id": "h_whQfJApBcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 1 - Podcast Extaction"
      ],
      "metadata": {
        "id": "BO37TXhVpucB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Enter in the Youtube Clip\n",
        "\n",
        "ex - https://www.youtube.com/watch?v=MVYrJJNdrEg&t=80s"
      ],
      "metadata": {
        "id": "etOOkIS3sZRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = input(\"Enter in the link to the podcast\")\n",
        "yt = YouTube(user_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C1OMkDQnp1IU",
        "outputId": "16ead574-6f1b-4725-ce89-f19bfea6b7ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter in the link to the podcasthttps://www.youtube.com/watch?v=MVYrJJNdrEg&t=80s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract all MP4 audio files"
      ],
      "metadata": {
        "id": "udQcERK0sfFp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "audio = yt.streams.filter(only_audio=True)\n",
        "for file in audio:\n",
        "    if file.mime_type == \"audio/mp4\":\n",
        "        stream = yt.streams.get_by_itag(file.itag)\n",
        "        print(f\"file - {file}\")\n",
        "        stream.download(filename='podcast.mp4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvJLoyeIsevf",
        "outputId": "ec7bd0f4-ba27-447a-c945-2558bddb8b5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file - <Stream: itag=\"139\" mime_type=\"audio/mp4\" abr=\"48kbps\" acodec=\"mp4a.40.5\" progressive=\"False\" type=\"audio\">\n",
            "file - <Stream: itag=\"140\" mime_type=\"audio/mp4\" abr=\"128kbps\" acodec=\"mp4a.40.2\" progressive=\"False\" type=\"audio\">\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the MP4 to MP3"
      ],
      "metadata": {
        "id": "m6TQ7DYq1G23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MP4ToMP3(mp4, mp3):\n",
        "    FILETOCONVERT = AudioFileClip(mp4)\n",
        "    FILETOCONVERT.write_audiofile(mp3)\n",
        "    FILETOCONVERT.close()\n",
        "\n",
        "VIDEO_FILE_PATH = \"podcast.mp4\"\n",
        "AUDIO_FILE_PATH = \"new_podcast.mp3\"\n",
        "MP4ToMP3(VIDEO_FILE_PATH, AUDIO_FILE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Za6n0bgx1VP3",
        "outputId": "d7f80d70-5be3-4d90-ee25-a58a2a47a907"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in new_podcast.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                       "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 2 - Audio Processing"
      ],
      "metadata": {
        "id": "51lft7wW2Oz_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Slice the MP3 audio file into 1 minute clips"
      ],
      "metadata": {
        "id": "tHLOr-G88Y-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "\n",
        "amt_of_clips = 0\n",
        "audio = AudioSegment.from_mp3(\"new_podcast.mp3\")\n",
        "one_minute = 1 * 60 * 1000\n",
        "out_path = './audio_clipss/'\n",
        "os.mkdir(out_path)\n",
        "start = 0\n",
        "end = one_minute\n",
        "minute = 1\n",
        "while end < len(audio):\n",
        "\n",
        "    end = min(end, len(audio))\n",
        "    new_chunk = audio[start:end]\n",
        "    new_chunk.export(out_path+f\"{minute}_minute.mp3\", format=\"mp3\")\n",
        "    minute += 1\n",
        "    start = end\n",
        "    end += one_minute\n",
        "    amt_of_clips+=1\n"
      ],
      "metadata": {
        "id": "99wmjdcf8S1W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "amt_of_clips"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVoOwDQthyZE",
        "outputId": "38cc0b74-652f-46f0-bc3d-fbe8da4b9cc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 3 - Transcribe audio files"
      ],
      "metadata": {
        "id": "uZjqHtfhAHh5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import OpenAIs Whisper"
      ],
      "metadata": {
        "id": "OltscOCkA70G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=\"ENTER YOUR KEY\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "kSsnSeEHAtzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizer to calculate amount of tokens needed"
      ],
      "metadata": {
        "id": "EsmON5FdJYwT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "#Create a length function\n",
        "def tiktoken_len(text):\n",
        "  tokens = tokenizer.encode(\n",
        "      text,\n",
        "      disallowed_special=()\n",
        "  )\n",
        "  return len(tokens)"
      ],
      "metadata": {
        "id": "dVtOqpe6Jgkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text Splitter function for chunking"
      ],
      "metadata": {
        "id": "i5AGHNjtJidi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 400,\n",
        "    chunk_overlap = 20,\n",
        "    length_function = tiktoken_len,\n",
        "    separators = ['\\n\\n', '\\n', ' ', '']\n",
        ")"
      ],
      "metadata": {
        "id": "hFv2kmMcJn3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Function to clean up text to reduce token usage"
      ],
      "metadata": {
        "id": "CseIpTF-ckn8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text_func(text):\n",
        "    clean_text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
        "    clean_text = re.sub(r'[ \\t]+', ' ', clean_text)\n",
        "    clean_text = re.sub(r'[\\n\\n]', '', clean_text)\n",
        "    return clean_text"
      ],
      "metadata": {
        "id": "Ai4lKc7Jcr6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transcribe all audio files"
      ],
      "metadata": {
        "id": "Sz-tB8V_BZtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_chunks = []\n",
        "for i in range(amt_of_clips):\n",
        "  a_f = open(\"./audio_clips/\" + f\"{i+1}\" + \"_minute.mp3\", \"rb\")\n",
        "  time_stamp = i\n",
        "  transcript = client.audio.transcriptions.create(\n",
        "  model=\"whisper-1\",\n",
        "  file=a_f\n",
        "  )\n",
        "  clean_transcript = clean_text_func(transcript.text)\n",
        "  list_of_chunks.append([clean_transcript, time_stamp])\n",
        "\n",
        "list_of_chunks"
      ],
      "metadata": {
        "id": "4Zmon-i7agjl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 4 - Embed Text and Store Vectors in Pinecone"
      ],
      "metadata": {
        "id": "5-RPDZIydOwn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Utilize OpenAI Embedding"
      ],
      "metadata": {
        "id": "gXZgTgWqdal_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = OpenAIEmbeddings(\n",
        "    model=\"text-embedding-ada-002\",\n",
        "    openai_api_key = \"ENTER YOUR KEY\"\n",
        ")"
      ],
      "metadata": {
        "id": "ME2YSifkdSIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create Pinecone Database"
      ],
      "metadata": {
        "id": "XzewXlyudyZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key = 'ENTER YOUR KEY',\n",
        "    environment = 'gcp-starter'\n",
        ")\n",
        "\n",
        "if 'yt-db' not in pinecone.list_indexes():\n",
        "  pinecone.create_index('yt-db', dimension = 1536)\n",
        "\n",
        "index = pinecone.Index('yt-db')\n"
      ],
      "metadata": {
        "id": "Kx4hswnHd0Un"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embed and Store Vectors"
      ],
      "metadata": {
        "id": "dFNJFnSle9Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 20\n",
        "\n",
        "for i in range(0, amt_of_clips,batch_size):\n",
        "  i_end = min(i+batch_size, amt_of_clips)\n",
        "  # IDs\n",
        "  ids = [str(n) for n in range(i,i_end)]\n",
        "  # Meta\n",
        "  meta = []\n",
        "  for x in range(i, i_end):\n",
        "    meta.append(\n",
        "        {\n",
        "          'text': list_of_chunks[x][0],\n",
        "          'timestamp':list_of_chunks[x][1]\n",
        "        }\n",
        "    )\n",
        "  #Embeddings\n",
        "  embeddings = []\n",
        "  for x in range(i,i_end):\n",
        "    embed = embed_model.embed_documents(list_of_chunks[x][0])\n",
        "    embeddings.append(embed[0])\n",
        "  index.upsert(vectors=zip(ids,embeddings,meta))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEb5npYRfA8Q",
        "outputId": "794ed335-2f07-425d-91c2-cae5a2a9d6fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amn =  64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Phase 5 Querying"
      ],
      "metadata": {
        "id": "QPb1iFtypidO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize ChatGPT and Pinecone"
      ],
      "metadata": {
        "id": "PfJ1nNfQplwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_field = \"text\"\n",
        "vectorstore = Pinecone(\n",
        "    index, embed_model, text_field\n",
        ")\n",
        "\n",
        "chat = ChatOpenAI(\n",
        "    openai_api_key=\"ENTER YOUR KEY\",\n",
        "    model=\"gpt-3.5-turbo\"\n",
        ")"
      ],
      "metadata": {
        "id": "4M4jnUmMKoQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize HyDE to be used in semantic searches"
      ],
      "metadata": {
        "id": "I2DM1VURK5aB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyDE_embedding = HypotheticalDocumentEmbedder.from_llm(\n",
        "    chat, embed_model, prompt_key=\"web_search\"\n",
        ")"
      ],
      "metadata": {
        "id": "_sWd7_BiNIBN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ask Away"
      ],
      "metadata": {
        "id": "iNx5zNIUNUxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def end_convo():\n",
        "  return False\n",
        "\n",
        "\n",
        "'''\n",
        "  Main portion of the program\n",
        "'''\n",
        "def continue_convo(messages):\n",
        "\n",
        "  timestamps = []\n",
        "  def augmented(query: str):\n",
        "    hyDE_ans = hyDE_embedding.embed_query(query)\n",
        "    results = index.query(top_k=3,vector = hyDE_ans, include_metadata=True)\n",
        "    source_knowledge = \"\\n\".join([x['metadata']['text'] for x in results['matches']])\n",
        "    #In Progress - Adding time stamps to print out for ref in the convo\n",
        "    '''\n",
        "    for t in results['matches']['metadata']['timestamp']:\n",
        "    timestamps.append(t)\n",
        "    '''\n",
        "    augmented_prompt = f\"\"\"Using the contexts below, answer the query.\n",
        "\n",
        "    Contexts:\n",
        "    {source_knowledge}\n",
        "\n",
        "    Query: {query}\"\"\"\n",
        "\n",
        "    return augmented_prompt\n",
        "  question = input(\"Enter in Question\")\n",
        "  prompt = HumanMessage(\n",
        "      content = augmented(question)\n",
        "  )\n",
        "  messages.append(prompt)\n",
        "  ai_response = chat(messages)\n",
        "  print(f\"AI: \\n{ai_response.content}\")\n",
        "  '''\n",
        "  print(\"Timestamp references(min)\\n\")\n",
        "  for t in timestamps:\n",
        "    print(t)\n",
        "  '''\n",
        "  messages.append(ai_response)\n",
        "  return True\n",
        "\n",
        "def new_convo():\n",
        "  messages.clear()\n",
        "  messages.append(SystemMessage(content=\"You are a helpful assistant\"))\n",
        "  return True\n",
        "\n",
        "def default_case():\n",
        "  print(\"Invalid Input\")\n",
        "  return True\n",
        "\n",
        "\n",
        "convo = True\n",
        "switch_dict = {\n",
        "      'E': end_convo,\n",
        "      'C': continue_convo,\n",
        "      'N': new_convo\n",
        "  }\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(content=\"You are a helpful assistant\")\n",
        "]\n",
        "while convo:\n",
        "  if len(messages) == 1:\n",
        "    print(\"Please ask a question to begin the conversation\")\n",
        "    continue_convo(messages)\n",
        "  else:\n",
        "    user_input = input(f\"End Conversation (E)\\nContinue Conversation(C)\\nNew Conversation(N)\")\n",
        "    action = switch_dict.get(user_input, default_case)\n",
        "\n",
        "    if action == continue_convo:\n",
        "      convo = action(messages)\n",
        "    else:\n",
        "      convo = action()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(\"convo over\")"
      ],
      "metadata": {
        "id": "JSvJ4oK1NnE7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}